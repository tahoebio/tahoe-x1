{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abafa220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/ahz/poetry_env/lib/python3.9/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "#import scvi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "#import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, eval_scib_metrics, load_pretrained\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716574d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewhz-zhang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/ahz/mosaicfm/wandb/run-20250226_002359-39t1s67u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewhz-zhang/scGPT/runs/39t1s67u\" target=\"_blank\">lemon-night-126</a></strong> to <a href=\"https://wandb.ai/andrewhz-zhang/scGPT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'dataset_name': 'norman', 'do_train': True, 'load_model': '/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model', 'model_name': 'best_model.pt', 'GEPC': True, 'ecs_thres': 0.8, 'dab_weight': 1.0, 'mask_ratio': 0.4, 'epochs': 15, 'n_bins': 51, 'lr': 0.0001, 'batch_size': 64, 'layer_size': 128, 'nlayers': 4, 'nhead': 4, 'dropout': 0.2, 'schedule_ratio': 0.9, 'save_eval_interval': 5, 'log_interval': 100, 'fast_transformer': True, 'pre_norm': False, 'amp': True}\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=42,\n",
    "    dataset_name=\"norman\", # Dataset name\n",
    "    do_train=True, # Flag to indicate whether to do update model parameters during training\n",
    "    load_model=\"/scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model\",\n",
    "    model_name=\"best_model.pt\",\n",
    "    GEPC=True,  # Gene expression modelling for cell objective\n",
    "    ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0, # DAR objective weight for batch correction\n",
    "    mask_ratio=0.4, # Default mask ratio\n",
    "    epochs=15, # Default number of epochs for fine-tuning\n",
    "    n_bins=51, # Default number of bins for value binning in data pre-processing\n",
    "    lr=1e-4, # Default learning rate for fine-tuning\n",
    "    batch_size=64, # Default batch size for fine-tuning\n",
    "    layer_size=128,\n",
    "    nlayers=4,\n",
    "    nhead=4, # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2, # Default dropout rate during model fine-tuning\n",
    "    schedule_ratio=0.9,  # Default rate for learning rate decay\n",
    "    save_eval_interval=5, # Default model evaluation interval\n",
    "    log_interval=100, # Default log interval\n",
    "    fast_transformer=True, # Default setting\n",
    "    pre_norm=False, # Default setting\n",
    "    amp=True,  # # Default setting: Automatic Mixed Precision\n",
    ")\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40811ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to /scratch/ssd004/scratch/ahz/perturb/dev_norman-Feb26-00-24\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# settings for input and preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = config.n_bins\n",
    "\n",
    "n_hvg = 1200  # number of highly variable genes\n",
    "max_seq_len = n_hvg + 1\n",
    "per_seq_batch_sample = True\n",
    "DSBN = False  # Domain-spec batchnorm\n",
    "explicit_zero_prob = True  # whether explicit bernoulli for zeros\n",
    "\n",
    "dataset_name = config.dataset_name\n",
    "save_dir = Path(f\"/scratch/ssd004/scratch/ahz/perturb/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a65666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21128b5",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset\n",
    "\n",
    "####  âœ… Note\n",
    "Perturbation datasets can be found in this path: `/scratch/ssd004/scratch/chloexq/perturb_analysis/{dataset_name}` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8699653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/scratch/ssd004/scratch/chloexq/perturb_analysis\")\n",
    "adata = sc.read(data_dir / \"norman/perturb_processed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db641f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 91205 Ã— 5045\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name'\n",
       "    var: 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b57b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index = pd.Index(adata.var[\"gene_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338c15de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AHR+FEV', 'AHR+KLF1', 'AHR+ctrl', 'ARID1A+ctrl', 'ARRDC3+ctrl',\n",
       "       'ATL1+ctrl', 'BAK1+ctrl', 'BCL2L11+BAK1', 'BCL2L11+TGFBR2',\n",
       "       'BCL2L11+ctrl', 'BCORL1+ctrl', 'BPGM+SAMD1', 'BPGM+ZBTB1',\n",
       "       'BPGM+ctrl', 'C19orf26+ctrl', 'C3orf72+FOXL2', 'C3orf72+ctrl',\n",
       "       'CBFA2T3+ctrl', 'CBL+CNN1', 'CBL+PTPN12', 'CBL+PTPN9',\n",
       "       'CBL+TGFBR2', 'CBL+UBASH3A', 'CBL+UBASH3B', 'CBL+ctrl',\n",
       "       'CDKN1A+ctrl', 'CDKN1B+CDKN1A', 'CDKN1B+ctrl', 'CDKN1C+CDKN1A',\n",
       "       'CDKN1C+CDKN1B', 'CDKN1C+ctrl', 'CEBPA+ctrl', 'CEBPB+CEBPA',\n",
       "       'CEBPB+MAPK1', 'CEBPB+OSR2', 'CEBPB+PTPN12', 'CEBPB+ctrl',\n",
       "       'CEBPE+CEBPA', 'CEBPE+CEBPB', 'CEBPE+CNN1', 'CEBPE+KLF1',\n",
       "       'CEBPE+PTPN12', 'CEBPE+RUNX1T1', 'CEBPE+SPI1', 'CEBPE+ctrl',\n",
       "       'CELF2+ctrl', 'CITED1+ctrl', 'CKS1B+ctrl', 'CLDN6+ctrl',\n",
       "       'CNN1+MAPK1', 'CNN1+UBASH3A', 'CNN1+ctrl', 'CNNM4+ctrl',\n",
       "       'COL1A1+ctrl', 'COL2A1+ctrl', 'CSRNP1+ctrl', 'DLX2+ctrl',\n",
       "       'DUSP9+ETS2', 'DUSP9+IGDCC3', 'DUSP9+KLF1', 'DUSP9+MAPK1',\n",
       "       'DUSP9+PRTG', 'DUSP9+SNAI1', 'DUSP9+ctrl', 'EGR1+ctrl',\n",
       "       'ELMSAN1+ctrl', 'ETS2+CEBPE', 'ETS2+CNN1', 'ETS2+IGDCC3',\n",
       "       'ETS2+IKZF3', 'ETS2+MAP7D1', 'ETS2+MAPK1', 'ETS2+PRTG',\n",
       "       'ETS2+ctrl', 'FEV+CBFA2T3', 'FEV+ISL2', 'FEV+MAP7D1', 'FEV+ctrl',\n",
       "       'FOSB+CEBPB', 'FOSB+CEBPE', 'FOSB+IKZF3', 'FOSB+OSR2',\n",
       "       'FOSB+PTPN12', 'FOSB+UBASH3B', 'FOSB+ctrl', 'FOXA1+FOXF1',\n",
       "       'FOXA1+FOXL2', 'FOXA1+HOXB9', 'FOXA1+ctrl', 'FOXA3+FOXA1',\n",
       "       'FOXA3+FOXF1', 'FOXA3+FOXL2', 'FOXA3+HOXB9', 'FOXA3+ctrl',\n",
       "       'FOXF1+FOXL2', 'FOXF1+HOXB9', 'FOXF1+ctrl', 'FOXL2+HOXB9',\n",
       "       'FOXL2+MEIS1', 'FOXL2+ctrl', 'FOXO4+ctrl', 'GLB1L2+ctrl',\n",
       "       'HES7+ctrl', 'HK2+ctrl', 'HNF4A+ctrl', 'HOXA13+ctrl', 'HOXB9+ctrl',\n",
       "       'HOXC13+ctrl', 'IER5L+ctrl', 'IGDCC3+MAPK1', 'IGDCC3+PRTG',\n",
       "       'IGDCC3+ZBTB25', 'IGDCC3+ctrl', 'IKZF3+ctrl', 'IRF1+SET',\n",
       "       'IRF1+ctrl', 'ISL2+ctrl', 'JUN+CEBPA', 'JUN+CEBPB', 'JUN+ctrl',\n",
       "       'KIAA1804+ctrl', 'KIF18B+KIF2C', 'KIF18B+ctrl', 'KIF2C+ctrl',\n",
       "       'KLF1+BAK1', 'KLF1+CEBPA', 'KLF1+CLDN6', 'KLF1+COL2A1',\n",
       "       'KLF1+FOXA1', 'KLF1+MAP2K6', 'KLF1+TGFBR2', 'KLF1+ctrl',\n",
       "       'KMT2A+ctrl', 'LHX1+ELMSAN1', 'LHX1+ctrl', 'LYL1+CEBPB',\n",
       "       'LYL1+IER5L', 'LYL1+ctrl', 'MAML2+ctrl', 'MAP2K3+ELMSAN1',\n",
       "       'MAP2K3+IKZF3', 'MAP2K3+MAP2K6', 'MAP2K3+SLC38A2', 'MAP2K3+ctrl',\n",
       "       'MAP2K6+ELMSAN1', 'MAP2K6+IKZF3', 'MAP2K6+SPI1', 'MAP2K6+ctrl',\n",
       "       'MAP4K3+ctrl', 'MAP4K5+ctrl', 'MAP7D1+ctrl', 'MAPK1+IKZF3',\n",
       "       'MAPK1+PRTG', 'MAPK1+TGFBR2', 'MAPK1+ctrl', 'MEIS1+ctrl',\n",
       "       'MIDN+ctrl', 'NCL+ctrl', 'NIT1+ctrl', 'OSR2+ctrl', 'PLK4+STIL',\n",
       "       'PLK4+ctrl', 'POU3F2+CBFA2T3', 'POU3F2+FOXL2', 'POU3F2+ctrl',\n",
       "       'PRDM1+CBFA2T3', 'PRDM1+ctrl', 'PRTG+ctrl', 'PTPN1+ctrl',\n",
       "       'PTPN12+OSR2', 'PTPN12+PTPN9', 'PTPN12+SNAI1', 'PTPN12+UBASH3A',\n",
       "       'PTPN12+ZBTB25', 'PTPN12+ctrl', 'PTPN13+ctrl', 'PTPN9+ctrl',\n",
       "       'RHOXF2BB+SET', 'RHOXF2BB+ZBTB25', 'RHOXF2BB+ctrl', 'RREB1+ctrl',\n",
       "       'RUNX1T1+ctrl', 'S1PR2+ctrl', 'SAMD1+PTPN12', 'SAMD1+TGFBR2',\n",
       "       'SAMD1+UBASH3B', 'SAMD1+ZBTB1', 'SAMD1+ctrl', 'SET+CEBPE',\n",
       "       'SET+KLF1', 'SET+ctrl', 'SGK1+S1PR2', 'SGK1+TBX2', 'SGK1+TBX3',\n",
       "       'SGK1+ctrl', 'SLC4A1+ctrl', 'SLC6A9+ctrl', 'SNAI1+DLX2',\n",
       "       'SNAI1+UBASH3B', 'SNAI1+ctrl', 'SPI1+ctrl', 'STIL+ctrl',\n",
       "       'TBX2+ctrl', 'TBX3+TBX2', 'TBX3+ctrl', 'TGFBR2+C19orf26',\n",
       "       'TGFBR2+ETS2', 'TGFBR2+IGDCC3', 'TGFBR2+PRTG', 'TGFBR2+ctrl',\n",
       "       'TMSB4X+BAK1', 'TMSB4X+ctrl', 'TP73+ctrl', 'TSC22D1+ctrl',\n",
       "       'UBASH3A+ctrl', 'UBASH3B+CNN1', 'UBASH3B+OSR2', 'UBASH3B+PTPN12',\n",
       "       'UBASH3B+PTPN9', 'UBASH3B+UBASH3A', 'UBASH3B+ZBTB25',\n",
       "       'UBASH3B+ctrl', 'ZBTB1+ctrl', 'ZBTB10+DLX2', 'ZBTB10+ELMSAN1',\n",
       "       'ZBTB10+PTPN12', 'ZBTB10+SNAI1', 'ZBTB10+ctrl', 'ZBTB25+ctrl',\n",
       "       'ZC3HAV1+CEBPA', 'ZC3HAV1+CEBPE', 'ZC3HAV1+HOXC13', 'ZC3HAV1+ctrl',\n",
       "       'ZNF318+FOXL2', 'ZNF318+ctrl', 'ctrl', 'ctrl+BAK1',\n",
       "       'ctrl+C19orf26', 'ctrl+CBFA2T3', 'ctrl+CDKN1A', 'ctrl+CDKN1B',\n",
       "       'ctrl+CEBPA', 'ctrl+CEBPB', 'ctrl+CEBPE', 'ctrl+CLDN6',\n",
       "       'ctrl+CNN1', 'ctrl+COL2A1', 'ctrl+DLX2', 'ctrl+ELMSAN1',\n",
       "       'ctrl+ETS2', 'ctrl+FEV', 'ctrl+FOXA1', 'ctrl+FOXF1', 'ctrl+FOXL2',\n",
       "       'ctrl+HOXB9', 'ctrl+HOXC13', 'ctrl+IER5L', 'ctrl+IGDCC3',\n",
       "       'ctrl+IKZF3', 'ctrl+ISL2', 'ctrl+KIF2C', 'ctrl+KLF1',\n",
       "       'ctrl+MAP2K6', 'ctrl+MAP7D1', 'ctrl+MAPK1', 'ctrl+MEIS1',\n",
       "       'ctrl+OSR2', 'ctrl+PRTG', 'ctrl+PTPN12', 'ctrl+PTPN9',\n",
       "       'ctrl+RUNX1T1', 'ctrl+SAMD1', 'ctrl+SET', 'ctrl+SLC38A2',\n",
       "       'ctrl+SNAI1', 'ctrl+SPI1', 'ctrl+STIL', 'ctrl+TBX2', 'ctrl+TBX3',\n",
       "       'ctrl+TGFBR2', 'ctrl+UBASH3A', 'ctrl+UBASH3B', 'ctrl+ZBTB1',\n",
       "       'ctrl+ZBTB25'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(adata.obs.condition.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544bacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(adata.obs.condition.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1338d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AHR+ctrl', 'ARID1A+ctrl', 'ARRDC3+ctrl', 'ATL1+ctrl', 'BAK1+ctrl', 'BCL2L11+ctrl', 'BCORL1+ctrl', 'BPGM+ctrl', 'C19orf26+ctrl', 'C3orf72+ctrl', 'CBFA2T3+ctrl', 'CBL+ctrl', 'CDKN1A+ctrl', 'CDKN1B+ctrl', 'CDKN1C+ctrl', 'CEBPA+ctrl', 'CEBPB+ctrl', 'CEBPE+ctrl', 'CELF2+ctrl', 'CITED1+ctrl', 'CKS1B+ctrl', 'CLDN6+ctrl', 'CNN1+ctrl', 'CNNM4+ctrl', 'COL1A1+ctrl', 'COL2A1+ctrl', 'CSRNP1+ctrl', 'DLX2+ctrl', 'DUSP9+ctrl', 'EGR1+ctrl', 'ELMSAN1+ctrl', 'ETS2+ctrl', 'FEV+ctrl', 'FOSB+ctrl', 'FOXA1+ctrl', 'FOXA3+ctrl', 'FOXF1+ctrl', 'FOXL2+ctrl', 'FOXO4+ctrl', 'GLB1L2+ctrl', 'HES7+ctrl', 'HK2+ctrl', 'HNF4A+ctrl', 'HOXA13+ctrl', 'HOXB9+ctrl', 'HOXC13+ctrl', 'IER5L+ctrl', 'IGDCC3+ctrl', 'IKZF3+ctrl', 'IRF1+ctrl', 'ISL2+ctrl', 'JUN+ctrl', 'KIAA1804+ctrl', 'KIF18B+ctrl', 'KIF2C+ctrl', 'KLF1+ctrl', 'KMT2A+ctrl', 'LHX1+ctrl', 'LYL1+ctrl', 'MAML2+ctrl', 'MAP2K3+ctrl', 'MAP2K6+ctrl', 'MAP4K3+ctrl', 'MAP4K5+ctrl', 'MAP7D1+ctrl', 'MAPK1+ctrl', 'MEIS1+ctrl', 'MIDN+ctrl', 'NCL+ctrl', 'NIT1+ctrl', 'OSR2+ctrl', 'PLK4+ctrl', 'POU3F2+ctrl', 'PRDM1+ctrl', 'PRTG+ctrl', 'PTPN1+ctrl', 'PTPN12+ctrl', 'PTPN13+ctrl', 'PTPN9+ctrl', 'RHOXF2BB+ctrl', 'RREB1+ctrl', 'RUNX1T1+ctrl', 'S1PR2+ctrl', 'SAMD1+ctrl', 'SET+ctrl', 'SGK1+ctrl', 'SLC4A1+ctrl', 'SLC6A9+ctrl', 'SNAI1+ctrl', 'SPI1+ctrl', 'STIL+ctrl', 'TBX2+ctrl', 'TBX3+ctrl', 'TGFBR2+ctrl', 'TMSB4X+ctrl', 'TP73+ctrl', 'TSC22D1+ctrl', 'UBASH3A+ctrl', 'UBASH3B+ctrl', 'ZBTB1+ctrl', 'ZBTB10+ctrl', 'ZBTB25+ctrl', 'ZC3HAV1+ctrl', 'ZNF318+ctrl', 'ctrl', 'ctrl+BAK1', 'ctrl+C19orf26', 'ctrl+CBFA2T3', 'ctrl+CDKN1A', 'ctrl+CDKN1B', 'ctrl+CEBPA', 'ctrl+CEBPB', 'ctrl+CEBPE', 'ctrl+CLDN6', 'ctrl+CNN1', 'ctrl+COL2A1', 'ctrl+DLX2', 'ctrl+ELMSAN1', 'ctrl+ETS2', 'ctrl+FEV', 'ctrl+FOXA1', 'ctrl+FOXF1', 'ctrl+FOXL2', 'ctrl+HOXB9', 'ctrl+HOXC13', 'ctrl+IER5L', 'ctrl+IGDCC3', 'ctrl+IKZF3', 'ctrl+ISL2', 'ctrl+KIF2C', 'ctrl+KLF1', 'ctrl+MAP2K6', 'ctrl+MAP7D1', 'ctrl+MAPK1', 'ctrl+MEIS1', 'ctrl+OSR2', 'ctrl+PRTG', 'ctrl+PTPN12', 'ctrl+PTPN9', 'ctrl+RUNX1T1', 'ctrl+SAMD1', 'ctrl+SET', 'ctrl+SLC38A2', 'ctrl+SNAI1', 'ctrl+SPI1', 'ctrl+STIL', 'ctrl+TBX2', 'ctrl+TBX3', 'ctrl+TGFBR2', 'ctrl+UBASH3A', 'ctrl+UBASH3B', 'ctrl+ZBTB1', 'ctrl+ZBTB25'] 153\n"
     ]
    }
   ],
   "source": [
    "single_gene_filter = [i for i in np.unique(adata.obs.condition.values) if not ('+' in i and 'ctrl' not in i)]\n",
    "print(single_gene_filter, len(single_gene_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af595f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs.condition.isin(single_gene_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7601f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 55760 Ã— 5045\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name'\n",
       "    var: 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a8b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update condition names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e80ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_batch_col = \"control\"\n",
    "adata.obs[\"celltype\"] = adata.obs[\"condition\"].astype(\"category\")\n",
    "adata.obs[\"str_batch\"] = adata.obs[\"control\"].astype(str)\n",
    "data_is_raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e74c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 4547/5045 genes in vocabulary of size 60697.\n",
      "Resume model from /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/best_model.pt, the model args will be overriden by the config /scratch/ssd004/scratch/chloexq/scGPT_models/scGPT_human_model/args.json.\n"
     ]
    }
   ],
   "source": [
    "if config.load_model is not None:\n",
    "    model_dir = Path(config.load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / config.model_name\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    print(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n",
    "    \n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    print(\n",
    "        f\"Resume model from {model_file}, the model args will be overriden by the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "else:\n",
    "    embsize = config.layer_size \n",
    "    nhead = config.nhead\n",
    "    nlayers = config.nlayers  \n",
    "    d_hid = config.layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e69a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names_set = [i + '+ctrl' for i in adata.var.gene_name.values]\n",
    "gene_names_set = gene_names_set + ['ctrl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933d35f",
   "metadata": {},
   "source": [
    "####  âœ… Note\n",
    "This experiment is computationally expensive, so we select 1000 cells per perturbation condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1185ae66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AHR+ctrl</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARID1A+ctrl</th>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARRDC3+ctrl</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL1+ctrl</th>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAK1+ctrl</th>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB1+ctrl</th>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB10+ctrl</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBTB25+ctrl</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZC3HAV1+ctrl</th>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF318+ctrl</th>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cell_type  dose_val  control  condition_name  celltype  \\\n",
       "condition                                                              \n",
       "AHR+ctrl            479       479      479             479       479   \n",
       "ARID1A+ctrl         182       182      182             182       182   \n",
       "ARRDC3+ctrl         405       405      405             405       405   \n",
       "ATL1+ctrl           305       305      305             305       305   \n",
       "BAK1+ctrl           534       534      534             534       534   \n",
       "...                 ...       ...      ...             ...       ...   \n",
       "ZBTB1+ctrl          315       315      315             315       315   \n",
       "ZBTB10+ctrl         145       145      145             145       145   \n",
       "ZBTB25+ctrl         343       343      343             343       343   \n",
       "ZC3HAV1+ctrl        436       436      436             436       436   \n",
       "ZNF318+ctrl         541       541      541             541       541   \n",
       "\n",
       "              str_batch  \n",
       "condition                \n",
       "AHR+ctrl            479  \n",
       "ARID1A+ctrl         182  \n",
       "ARRDC3+ctrl         405  \n",
       "ATL1+ctrl           305  \n",
       "BAK1+ctrl           534  \n",
       "...                 ...  \n",
       "ZBTB1+ctrl          315  \n",
       "ZBTB10+ctrl         145  \n",
       "ZBTB25+ctrl         343  \n",
       "ZC3HAV1+ctrl        436  \n",
       "ZNF318+ctrl         541  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap all conditions to 1000 cells\n",
    "sampled_df = (\n",
    "    adata.obs[adata.obs['condition'].isin(gene_names_set)]\n",
    "    .groupby('condition', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), 1000), random_state=42))\n",
    ")\n",
    "adata = adata[sampled_df.index].copy()\n",
    "adata.obs.groupby('condition').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f2e8155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "      <th>celltype</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cell_type  dose_val  control  condition_name  celltype  str_batch\n",
       "condition                                                                   \n",
       "ctrl          1000.0    1000.0   1000.0          1000.0    1000.0     1000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 conditions are capped, including ctrl\n",
    "condition_counts = adata.obs.groupby('condition').count()\n",
    "condition_counts[condition_counts == 1000].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "926217f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = set(adata.obs.condition.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20cf69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names.remove('ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9982e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene = [i.split('+')[0] for i in list(condition_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da55a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names_gene.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72c6da",
   "metadata": {},
   "source": [
    "####  âœ… Note\n",
    "HVGs selection will filter out some perturbed genes. We manually add them back in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5874e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n"
     ]
    }
   ],
   "source": [
    "# Do filtering\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=3,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    #binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    #result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4100ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    layer=None,\n",
    "    n_top_genes=1200,\n",
    "    flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    subset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f73f0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_counter = 0\n",
    "for g in condition_names_gene:\n",
    "    if not adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'].values[0]:\n",
    "        adata.var.loc[adata.var[adata.var.gene_name==g].index, 'highly_variable'] = True\n",
    "        add_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0196dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually add conditions: 67, 0.6767676767676768\n"
     ]
    }
   ],
   "source": [
    "print('Manually add conditions: {}, {}'.format(add_counter, add_counter/len(condition_names_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a644f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "# This step for binning\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=0,  # step 1\n",
    "    filter_cell_by_counts=None,  # step 2\n",
    "    normalize_total=None,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=None,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab55acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs Ã— n_vars = 33059 Ã— 1267\n",
      "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch'\n",
      "    var: 'gene_name', 'id_in_vocab', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n",
      "    obsm: 'bin_edges'\n",
      "    layers: 'counts', 'X_binned'\n"
     ]
    }
   ],
   "source": [
    "adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526d709",
   "metadata": {},
   "source": [
    "#### ðŸ”µ Optional\n",
    "Create another randomly shuffled list of `condition_names_gene_match` as control, if running the control experiment. \n",
    "Note that there are many ways to construct the control list, either from perturbation targets or random from all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c8e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of randomly shuffle perturbation targets\n",
    "import random\n",
    "random.seed(42)\n",
    "condition_names_gene_match = condition_names_gene.copy()\n",
    "random.shuffle(condition_names_gene_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f5baedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of using non-targets\n",
    "# This is the most recent version\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "non_targets = list(set(genes).difference(set(condition_names_gene)))\n",
    "non_targets.sort()\n",
    "random.seed(42)\n",
    "random.shuffle(non_targets)\n",
    "non_targets\n",
    "condition_names_gene_match = non_targets[:len(condition_names_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b2320a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AHR', 'ARID1A', 'ARRDC3', 'ATL1', 'BAK1', 'BCL2L11', 'BCORL1', 'BPGM', 'CBFA2T3', 'CBL', 'CDKN1A', 'CDKN1B', 'CDKN1C', 'CEBPA', 'CEBPB', 'CEBPE', 'CELF2', 'CITED1', 'CKS1B', 'CLDN6', 'CNN1', 'CNNM4', 'COL1A1', 'COL2A1', 'CSRNP1', 'DLX2', 'DUSP9', 'EGR1', 'ETS2', 'FEV', 'FOSB', 'FOXA1', 'FOXA3', 'FOXF1', 'FOXL2', 'FOXO4', 'GLB1L2', 'HES7', 'HK2', 'HNF4A', 'HOXA13', 'HOXB9', 'HOXC13', 'IER5L', 'IGDCC3', 'IKZF3', 'IRF1', 'ISL2', 'JUN', 'KIF18B', 'KIF2C', 'KLF1', 'KMT2A', 'LHX1', 'LYL1', 'MAML2', 'MAP2K3', 'MAP2K6', 'MAP4K3', 'MAP4K5', 'MAP7D1', 'MAPK1', 'MEIS1', 'MIDN', 'NCL', 'NIT1', 'OSR2', 'PLK4', 'POU3F2', 'PRDM1', 'PRTG', 'PTPN1', 'PTPN12', 'PTPN13', 'PTPN9', 'RREB1', 'RUNX1T1', 'S1PR2', 'SAMD1', 'SET', 'SGK1', 'SLC4A1', 'SLC6A9', 'SNAI1', 'SPI1', 'STIL', 'TBX2', 'TBX3', 'TGFBR2', 'TMSB4X', 'TP73', 'TSC22D1', 'UBASH3A', 'UBASH3B', 'ZBTB1', 'ZBTB10', 'ZBTB25', 'ZC3HAV1', 'ZNF318']\n"
     ]
    }
   ],
   "source": [
    "print(condition_names_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91295c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RASSF4', 'FUT7', 'IL22RA2', 'IP6K3', 'MANF', 'TIMP1', 'MLC1', 'ATF4', 'OR51E1', 'CTD-2623N2.5', 'OS9', 'CYSLTR2', 'ST3GAL6', 'LINC00895', 'HEATR9', 'ANXA2R', 'PMEPA1', 'RP11-46D6.1', 'PDE4DIP', 'RP11-404F10.2', 'APOBEC3D', 'MAOB', 'RP11-90K6.1', 'CD244', 'SVEP1', 'MEIS3', 'GHRL', 'RP11-212I21.4', 'IL6ST', 'ABCA1', 'SLC2A1-AS1', 'CTSO', 'RP11-306G20.1', 'TMEM154', 'PCAT5', 'RP11-443B7.2', 'PCDH9', 'TUBB3', 'SMYD3', 'TRAC', 'PARVG', 'NUTM2G', 'ERP27', 'GDF15', 'RP11-727F15.9', 'RP11-887P2.5', 'HBG2', 'RP5-1086K13.1', 'IRF2BP2', 'PDZK1IP1', 'TEX13D', 'RP11-498P14.5', 'PLAC8', 'C20orf202', 'BTG1', 'GPC1', 'REN', 'HBA2', 'ALDH3B1', 'AC002463.3', 'IL3RA', 'CABP4', 'ICOSLG', 'TXNIP', 'TNFRSF14', 'RP1-286D6.5', 'RP11-1152H14.1', 'EVI2B', 'PPP3CA', 'HBG1', 'PRSS57', 'CD48', 'RNF213', 'EPX', 'CD2', 'TMEM150C', 'FAM166B', 'PNOC', 'IL20', 'TCP11L2', 'CLEC4D', 'AC005616.2', 'SVOPL', 'RAP2C-AS1', 'OPRL1', 'ADIRF', 'PHLDA1', 'ARMCX3', 'FAM234A', 'OSBPL10', 'VWA7', 'ID2-AS1', 'ADRB2', 'ACE', 'ATP10D', 'SP6', 'SMOX', 'MS4A3', 'SYT4']\n"
     ]
    }
   ],
   "source": [
    "print(condition_names_gene_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8a4f5",
   "metadata": {},
   "source": [
    "## Prepare model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ebbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = adata.shape[1] + 1\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3663c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)\n",
    "adata.obs['batch_id'] = adata.obs['condition'].copy()\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "input_layer_key = \"X_binned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5753701",
   "metadata": {},
   "source": [
    "## Load the pre-trained scGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e346fb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    dropout=config.dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=config.GEPC,\n",
    "    do_dab=False,\n",
    "    use_batch_labels=False,\n",
    "    num_batch_labels=num_batch_types,\n",
    "    domain_spec_batchnorm=DSBN,\n",
    "    n_input_bins=n_input_bins,\n",
    "    ecs_threshold=config.ecs_thres,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=config.fast_transformer,\n",
    "    use_generative_training=True,\n",
    "    pre_norm=config.pre_norm,\n",
    ")\n",
    "if config.load_model is not None:\n",
    "    load_pretrained(model, torch.load(model_file), verbose=False)\n",
    "\n",
    "model.to(device)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd1c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "adata_t = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca655eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = (\n",
    "    adata_t.layers[input_layer_key].A\n",
    "    if issparse(adata_t.layers[input_layer_key])\n",
    "    else adata_t.layers[input_layer_key]\n",
    ")\n",
    "celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "batch_ids = np.array(batch_ids)\n",
    "\n",
    "tokenized_all = tokenize_and_pad_batch(\n",
    "    all_counts,\n",
    "    gene_ids,\n",
    "    max_len=max_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=True,\n",
    ")\n",
    "all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900efa46",
   "metadata": {},
   "source": [
    "##  Get gene embeddings (with Value Masking), Calculate Cosine Distance & Rank, and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6647b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cell(tokenized_all, key, k, select_gene_id):\n",
    "    cell_k = tokenized_all[key][k]\n",
    "    # Repeat \n",
    "    cell_k_expand = cell_k.repeat(n_genes).view(n_genes, n_genes)\n",
    "    new_column = torch.full((n_genes, 1), vocab([pad_token])[0])\n",
    "    cell_k_expand = torch.cat((cell_k_expand, new_column), dim=1)\n",
    "    mask = torch.eye(n_genes).bool()\n",
    "    new_column_mask = torch.full((n_genes, 1), False)\n",
    "    mask = torch.cat((mask, new_column_mask), dim=1)\n",
    "    mask[:, select_gene_id] = True\n",
    "    mask[select_gene_id, n_genes] = True\n",
    "    mask_select_expand = cell_k_expand[mask]\n",
    "    select_ids_gen = mask_select_expand.view(n_genes, 2)\n",
    "    select_ids_pcpt = cell_k_expand[~mask].view(n_genes, n_genes-1)\n",
    "    return select_ids_gen, select_ids_pcpt\n",
    "\n",
    "from tqdm import tqdm\n",
    "def collate_cell_by_key(tokenized_all, key, select_gene_id):\n",
    "    print(key)\n",
    "    select_ids_gen_list = []\n",
    "    select_ids_pcpt_list = []\n",
    "    for k in tqdm(range(n_cells)):\n",
    "        select_ids_gen, select_ids_pcpt = expand_cell(tokenized_all, key, k, select_gene_id)\n",
    "        select_ids_gen_list.append(select_ids_gen)\n",
    "        select_ids_pcpt_list.append(select_ids_pcpt)\n",
    "    select_ids_gen = torch.cat(select_ids_gen_list, dim=0)\n",
    "    select_ids_pcpt = torch.cat(select_ids_pcpt_list, dim=0)\n",
    "    print(select_ids_gen.shape, select_ids_pcpt.shape)\n",
    "    return select_ids_gen, select_ids_pcpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58607d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0b7c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_barcode\n",
      "GCTGCGACAAACTGTC-2    AHR+ctrl\n",
      "GCGCAACTCAGGTAAA-6    AHR+ctrl\n",
      "TGCGTGGTCTCGATGA-1    AHR+ctrl\n",
      "CGATGTATCTGGCGAC-1    AHR+ctrl\n",
      "GCGAGAACAGATGGCA-8    AHR+ctrl\n",
      "                        ...   \n",
      "TATCAGGGTAGCTGCC-6        ctrl\n",
      "AGTCTTTTCTCTTATG-4        ctrl\n",
      "ACGAGGAAGGCAGGTT-3        ctrl\n",
      "GACTGCGTCCTCCTAG-8        ctrl\n",
      "CAACTAGGTAGCGTCC-4        ctrl\n",
      "Name: condition, Length: 1479, dtype: category\n",
      "Categories (2, object): ['AHR+ctrl', 'ctrl']\n",
      "439\n",
      "torch.Size([1479, 1268]) torch.Size([1479, 1268])\n",
      "genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1479/1479 [00:07<00:00, 200.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1875372, 2]) torch.Size([1875372, 1267])\n",
      "values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1479/1479 [00:06<00:00, 218.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1875372, 2]) torch.Size([1875372, 1267])\n",
      "{'genes_pcpt': tensor([[24904, 30607, 21504,  ..., 12288, 12289, 60694],\n",
      "        [60695, 30607, 21504,  ..., 12288, 12289, 60694],\n",
      "        [60695, 24904, 21504,  ..., 12288, 12289, 60694],\n",
      "        ...,\n",
      "        [60695, 24904, 30607,  ..., 12288, 12289, 60694],\n",
      "        [60695, 24904, 30607,  ..., 11394, 12289, 60694],\n",
      "        [60695, 24904, 30607,  ..., 11394, 12288, 60694]]), 'genes_gen': tensor([[60695,  1743],\n",
      "        [24904,  1743],\n",
      "        [30607,  1743],\n",
      "        ...,\n",
      "        [ 1743, 11394],\n",
      "        [ 1743, 12288],\n",
      "        [ 1743, 12289]]), 'values_pcpt': tensor([[    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        ...,\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.],\n",
      "        [    0.,     0.,     0.,  ...,     0.,     0., 60694.]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                   | 1039/3663 [34:23<1:26:52,  1.99s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "select_gene_list = condition_names_gene\n",
    "\n",
    "for select_gene in select_gene_list:\n",
    "    adata_t = adata[adata.obs['condition'].isin([select_gene+'+ctrl', 'ctrl'])].copy()\n",
    "    print(adata_t.obs['condition'])\n",
    "    select_gene_id = genes.index(select_gene)+1\n",
    "    print(select_gene_id)\n",
    "    all_counts = (\n",
    "        adata_t.layers[input_layer_key].A\n",
    "        if issparse(adata_t.layers[input_layer_key])\n",
    "        else adata_t.layers[input_layer_key]\n",
    "    )\n",
    "    celltypes_labels = adata_t.obs[\"celltype\"].tolist()\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    batch_ids = adata_t.obs[\"batch_id\"].tolist()\n",
    "    batch_ids = np.array(batch_ids)\n",
    "\n",
    "    tokenized_all = tokenize_and_pad_batch(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=True,\n",
    "    )\n",
    "    all_gene_ids, all_values = tokenized_all[\"genes\"], tokenized_all[\"values\"]\n",
    "    src_key_padding_mask = all_gene_ids.eq(vocab[pad_token])\n",
    "    print(tokenized_all['genes'].shape, tokenized_all['values'].shape)\n",
    "    n_cells = tokenized_all['genes'].shape[0]\n",
    "    n_genes = tokenized_all['genes'].shape[1]\n",
    "    \n",
    "    collate_genes_gen, collate_genes_pcpt = collate_cell_by_key(tokenized_all, 'genes', select_gene_id)\n",
    "    _, collate_values_pcpt = collate_cell_by_key(tokenized_all, 'values', select_gene_id)\n",
    "    \n",
    "    tokenized_all_expand = {'genes_pcpt': collate_genes_pcpt, 'genes_gen': collate_genes_gen, 'values_pcpt': collate_values_pcpt}\n",
    "    print(tokenized_all_expand)\n",
    "    query_id = tokenized_all['genes'][0].repeat(n_cells)\n",
    "    \n",
    "    cell_counter = torch.arange(0, n_cells)\n",
    "    cell_counter = cell_counter.repeat(n_genes).view(n_genes, n_cells).t().flatten()\n",
    "    gene_counter = torch.arange(0, n_genes).repeat(n_cells)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        TensorDataset(tokenized_all_expand['genes_pcpt'], \n",
    "                      tokenized_all_expand['genes_gen'], \n",
    "                      tokenized_all_expand['values_pcpt'],\n",
    "                      query_id,\n",
    "                      cell_counter,\n",
    "                      gene_counter,\n",
    "                     ), \n",
    "        batch_size=512, \n",
    "        shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    gene_embeddings = np.zeros((n_cells, n_genes, 512))\n",
    "    \n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=config.amp):\n",
    "        for batch_idx, batch_data in enumerate(tqdm(dataloader)):\n",
    "            pcpt_genes = batch_data[0].to(device)\n",
    "            gen_genes = batch_data[1].to(device)\n",
    "            pcpt_values = batch_data[2].to(device)\n",
    "            query_id_select = batch_data[3].to(device)\n",
    "            cell_counter_batch = batch_data[4].to(device)\n",
    "            gene_counter_batch = batch_data[5].to(device)\n",
    "            pcpt_key_padding_mask = pcpt_genes.eq(vocab[pad_token]).to(device)\n",
    "            gen_key_padding_mask = gen_genes.eq(vocab[pad_token]).to(device)\n",
    "            _, gen_output = model.transformer_generate(\n",
    "                pcpt_genes=pcpt_genes,\n",
    "                pcpt_values=pcpt_values,\n",
    "                pcpt_key_padding_mask=pcpt_key_padding_mask,\n",
    "                gen_genes=gen_genes,\n",
    "                gen_key_padding_mask=gen_key_padding_mask,\n",
    "            )\n",
    "            select_mask = (gen_genes == query_id_select.unsqueeze(1)).long()\n",
    "            selected_output = gen_output[torch.arange(gen_output.shape[0]), select_mask.argmax(dim=1), :]\n",
    "            selected_output_np = selected_output.detach().cpu().numpy()\n",
    "            gene_embeddings[cell_counter_batch.detach().cpu().numpy(), gene_counter_batch.detach().cpu().numpy(), :] = selected_output_np\n",
    "    \n",
    "    conditions = adata_t.obs['condition'].values\n",
    "    \n",
    "    dict_sum_condition_mean = {}\n",
    "    for c in np.unique(conditions):\n",
    "        dict_sum_condition_mean[c] = gene_embeddings[np.where(conditions == c)[0]].mean(0)\n",
    "    \n",
    "    print(dict_sum_condition_mean)\n",
    "        \n",
    "    celltype_0 = select_gene + '+ctrl'\n",
    "    celltype_1 = 'ctrl'\n",
    "    gene_emb_celltype_0 = np.expand_dims(dict_sum_condition_mean[celltype_0][1:, 1:], 0)\n",
    "    gene_emb_celltype_1 = np.expand_dims(dict_sum_condition_mean[celltype_1][1:, 1:], 0)\n",
    "    gene_dist_dict = {}\n",
    "    for i, g in tqdm(enumerate(genes)):\n",
    "        gene_dist_dict[g] = cosine_distances(gene_emb_celltype_0[:, i, :], gene_emb_celltype_1[:, i, :]).mean()\n",
    "    df_gene_emb_dist = pd.DataFrame.from_dict(gene_dist_dict, orient='index', columns=['cos_dist'])\n",
    "    df_deg = df_gene_emb_dist.sort_values(by='cos_dist', ascending=False)\n",
    "    rank_celltype_0 = np.where(df_deg.index==celltype_0.split('+')[0])[0][0]\n",
    "    print(celltype_0, rank_celltype_0) \n",
    "    np.savez(str(save_dir)+\"mean_gene_emb_{}_{}.npz\".format(select_gene, rank_celltype_0), **dict_sum_condition_mean)\n",
    "    print(f'Saved:\\n{str(save_dir)+\"mean_gene_emb_{}_{}.npz\".format(select_gene, rank_celltype_0)}')\n",
    "    assert(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
