integrations:
- integration_type: pip_packages
  packages:
    - llm-foundry==0.6.0
    - mosaicml[deepspeed]
- integration_type: git_repo
  git_repo: vevotx/vevo-scGPT
  git_branch: dev-temp
  # git_commit:  # OR use your commit hash
  pip_install: -e .
  ssh_clone: true  # Should be true if using a private repo

# We are fetching, converting, and training on the 'val' split
# as it is small and quick to get going for this demo.
# For real training runs, follow the instructions in `llm-foundry/scripts/train/README.md`
# to convert and host the full 'train' dataset.
command: |
  cd vevo-scGPT/examples
  composer pretrain_composer.py
image: mosaicml/llm-foundry:2.2.1_cu121_flash2-latest
env_variables:
  MOSAICML_PLATFORM: False #Logging metadata to MosaicML platform is disabled, since it seems to timeout
name: scgpt-1b-gpus-8

compute:
  gpus: 8  # Number of GPUs to use
  cluster: r4z8
scheduling:
  max_duration: 0.1 # Maximum duration of the run in hours

  ## These configurations are optional
  # cluster: # TODO # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use. We use a100_80gb in our experiments


# The below is injected as a YAML file: /mnt/config/parameters.yaml
# but is not used in this example.
parameters: {}